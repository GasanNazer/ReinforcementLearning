{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03cab62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stable-baselines\n",
    "#Download and install ROMs\n",
    "#!gdown -q http://www.atarimania.com/roms/Roms.rar\n",
    "#!pip install -q unrar\n",
    "#!mkdir ./roms_atari\n",
    "#!unrar x Roms.rar ./roms_atari > /dev/null 2>&1\n",
    "#!python -m atari_py.import_roms ./roms_atari > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46855b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "#from google.colab import drive\n",
    "import gym.wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3df1447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b7829880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"BreakoutNoFrameskip-v4\") #make_atari\n",
    "obs = np.array(env.reset())\n",
    "print(obs.shape)\n",
    "plt.title(\"what the raw input looks like\")\n",
    "plt.imshow(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1eda70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 84, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b65e77f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obseravtions (wrapped)\n",
    "env = gym.make(\"BreakoutNoFrameskip-v4\") #make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "obs = np.array(env.reset())\n",
    "\n",
    "print(obs.shape)\n",
    "plt.title(\"agent observation (4 frames)\")\n",
    "plt.imshow(obs.transpose([0, 2, 1]).reshape([env.observation_space.shape[0], -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cd6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
     ]
    }
   ],
   "source": [
    "# Actions\n",
    "print(env.action_space)\n",
    "print(env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c8feb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b812b2b0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rewards\n",
    "env.reset()\n",
    "rewards = []\n",
    "while True:\n",
    "    obs, rew, done, info = env.step(env.action_space.sample())\n",
    "    rewards.append(rew)\n",
    "    if done:\n",
    "        break\n",
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d3e53ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 84, 84, 4)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 20, 20, 16)        4112      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 9, 9, 32)          8224      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2592)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               663808    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 677,172\n",
      "Trainable params: 677,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:16:01.510090: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-17 13:16:01.510296: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "num_actions = 4\n",
    "def create_q_model():\n",
    "    # Network defined by the Deepmind paper\n",
    "    inputs = layers.Input(shape=(84, 84, 4,))\n",
    "\n",
    "    layer1 = layers.Conv2D(16, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(32, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    #layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer3 = layers.Flatten()(layer2)\n",
    "    layer4 = layers.Dense(256, activation=\"relu\")(layer3)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer4)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=action)\n",
    "\n",
    "# The first model makes the predictions for Q-values which are used to make a action.\n",
    "model = create_q_model()\n",
    "# Target model\n",
    "model_target = create_q_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af88ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99  # Discount factor for past rewards\n",
    "\n",
    "# Setting epsilon decay parameters\n",
    "epsilon = 1.0  \n",
    "epsilon_max_1 = 1.0 \n",
    "epsilon_min_1 = 0.2  \n",
    "epsilon_max_2 = epsilon_min_1  \n",
    "epsilon_min_2 = 0.1\n",
    "epsilon_max_3 = epsilon_min_2  \n",
    "epsilon_min_3 = 0.02\n",
    "\n",
    "epsilon_interval_1 = (epsilon_max_1 - epsilon_min_1)  \n",
    "epsilon_interval_2 = (epsilon_max_2 - epsilon_min_2)  \n",
    "epsilon_interval_3 = (epsilon_max_3 - epsilon_min_3)  \n",
    "\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 1000000.0\n",
    "\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "\n",
    "# Maximum Replay Buffer volume\n",
    "max_memory_length = 190000\n",
    "\n",
    "# Size of batch taken from replay buffer\n",
    "batch_size = 32  \n",
    "max_steps_per_episode = 10000\n",
    "\n",
    "# Train the model after 20 actions\n",
    "update_after_actions = 20\n",
    "\n",
    "# How often to update the target network\n",
    "update_target_network = 10000\n",
    "\n",
    "# In the Deepmind paper they use RMSProp however then Adam optimizer improves training time\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "\n",
    "# Using huber loss for stability\n",
    "loss_function = keras.losses.Huber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9bdb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "#model_name = 'breakout_model_1'\n",
    "#path = F\"/content/gdrive/MyDrive/models/{model_name}\" \n",
    "#model.save(path)\n",
    "\n",
    "# Loading the model\n",
    "# model = tf.keras.models.load_model(path)\n",
    "def save_model(episode):\n",
    "    model_name = f'breakout_beta_progress_episodes_{episode}.44'\n",
    "    path = f\"./{model_name}\"\n",
    "    model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba66d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:17:14.125648: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-06-17 13:17:14.125881: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-17 13:17:14.177784: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reward: 0.10 at episode 90, frame count 10000, epsilon 0.992, loss 0.01734\n",
      "running reward: 0.05 at episode 186, frame count 20000, epsilon 0.984, loss 0.01653\n",
      "running reward: 0.02 at episode 288, frame count 30000, epsilon 0.976, loss 0.03171\n",
      "running reward: 0.07 at episode 382, frame count 40000, epsilon 0.968, loss 0.00013\n",
      "running reward: 0.17 at episode 460, frame count 50000, epsilon 0.960, loss 0.00016\n",
      "running reward: 0.12 at episode 545, frame count 60000, epsilon 0.952, loss 0.00019\n",
      "running reward: 0.16 at episode 633, frame count 70000, epsilon 0.944, loss 0.00033\n",
      "running reward: 0.13 at episode 719, frame count 80000, epsilon 0.936, loss 0.00030\n",
      "running reward: 0.12 at episode 807, frame count 90000, epsilon 0.928, loss 0.00017\n",
      "running reward: 0.05 at episode 904, frame count 100000, epsilon 0.920, loss 0.00007\n",
      "running reward: 0.06 at episode 997, frame count 110000, epsilon 0.912, loss 0.00019\n",
      "running reward: 0.13 at episode 1082, frame count 120000, epsilon 0.904, loss 0.00030\n",
      "running reward: 0.06 at episode 1178, frame count 130000, epsilon 0.896, loss 0.00017\n",
      "running reward: 0.04 at episode 1276, frame count 140000, epsilon 0.888, loss 0.00011\n",
      "running reward: 0.08 at episode 1368, frame count 150000, epsilon 0.880, loss 0.00874\n",
      "running reward: 0.07 at episode 1462, frame count 160000, epsilon 0.872, loss 0.00018\n",
      "running reward: 0.06 at episode 1558, frame count 170000, epsilon 0.864, loss 0.00018\n",
      "running reward: 0.14 at episode 1646, frame count 180000, epsilon 0.856, loss 0.00009\n",
      "running reward: 0.10 at episode 1738, frame count 190000, epsilon 0.848, loss 0.00043\n",
      "running reward: 0.19 at episode 1815, frame count 200000, epsilon 0.840, loss 0.00012\n",
      "running reward: 0.18 at episode 1900, frame count 210000, epsilon 0.832, loss 0.00730\n",
      "running reward: 0.12 at episode 1992, frame count 220000, epsilon 0.824, loss 0.00009\n",
      "running reward: 0.03 at episode 2092, frame count 230000, epsilon 0.816, loss 0.00661\n",
      "running reward: 0.13 at episode 2177, frame count 240000, epsilon 0.808, loss 0.00020\n",
      "running reward: 0.08 at episode 2272, frame count 250000, epsilon 0.800, loss 0.00523\n",
      "running reward: 0.18 at episode 2349, frame count 260000, epsilon 0.792, loss 0.00018\n",
      "running reward: 0.15 at episode 2437, frame count 270000, epsilon 0.784, loss 0.00016\n",
      "running reward: 0.07 at episode 2531, frame count 280000, epsilon 0.776, loss 0.00039\n",
      "running reward: 0.10 at episode 2622, frame count 290000, epsilon 0.768, loss 0.01156\n",
      "running reward: 0.15 at episode 2709, frame count 300000, epsilon 0.760, loss 0.00371\n",
      "running reward: 0.06 at episode 2803, frame count 310000, epsilon 0.752, loss 0.00020\n",
      "running reward: 0.12 at episode 2887, frame count 320000, epsilon 0.744, loss 0.00013\n",
      "running reward: 0.11 at episode 2978, frame count 330000, epsilon 0.736, loss 0.00599\n",
      "running reward: 0.08 at episode 3074, frame count 340000, epsilon 0.728, loss 0.00006\n",
      "running reward: 0.15 at episode 3159, frame count 350000, epsilon 0.720, loss 0.00341\n",
      "running reward: 0.06 at episode 3257, frame count 360000, epsilon 0.712, loss 0.00055\n",
      "running reward: 0.14 at episode 3341, frame count 370000, epsilon 0.704, loss 0.00022\n",
      "running reward: 0.19 at episode 3420, frame count 380000, epsilon 0.696, loss 0.00897\n",
      "running reward: 0.17 at episode 3506, frame count 390000, epsilon 0.688, loss 0.00028\n",
      "running reward: 0.15 at episode 3590, frame count 400000, epsilon 0.680, loss 0.00015\n",
      "running reward: 0.25 at episode 3671, frame count 410000, epsilon 0.672, loss 0.00012\n",
      "running reward: 0.17 at episode 3757, frame count 420000, epsilon 0.664, loss 0.00012\n",
      "running reward: 0.03 at episode 3857, frame count 430000, epsilon 0.656, loss 0.00043\n",
      "running reward: 0.18 at episode 3938, frame count 440000, epsilon 0.648, loss 0.00053\n",
      "running reward: 0.13 at episode 4024, frame count 450000, epsilon 0.640, loss 0.00060\n",
      "running reward: 0.13 at episode 4110, frame count 460000, epsilon 0.632, loss 0.00015\n",
      "running reward: 0.20 at episode 4192, frame count 470000, epsilon 0.624, loss 0.00021\n",
      "running reward: 0.15 at episode 4281, frame count 480000, epsilon 0.616, loss 0.00018\n",
      "running reward: 0.19 at episode 4370, frame count 490000, epsilon 0.608, loss 0.00013\n",
      "running reward: 0.11 at episode 4463, frame count 500000, epsilon 0.600, loss 0.00050\n",
      "running reward: 0.17 at episode 4547, frame count 510000, epsilon 0.592, loss 0.00027\n",
      "running reward: 0.21 at episode 4627, frame count 520000, epsilon 0.584, loss 0.00018\n",
      "running reward: 0.16 at episode 4714, frame count 530000, epsilon 0.576, loss 0.01332\n",
      "running reward: 0.13 at episode 4801, frame count 540000, epsilon 0.568, loss 0.00062\n",
      "running reward: 0.12 at episode 4888, frame count 550000, epsilon 0.560, loss 0.00026\n",
      "running reward: 0.18 at episode 4968, frame count 560000, epsilon 0.552, loss 0.00034\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./breakout_beta_progress_episodes_5000.44/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-17 13:51:04.754545: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running reward: 0.25 at episode 5045, frame count 570000, epsilon 0.544, loss 0.00024\n",
      "running reward: 0.32 at episode 5113, frame count 580000, epsilon 0.536, loss 0.00011\n",
      "running reward: 0.32 at episode 5192, frame count 590000, epsilon 0.528, loss 0.00223\n",
      "running reward: 0.19 at episode 5272, frame count 600000, epsilon 0.520, loss 0.00025\n",
      "running reward: 0.23 at episode 5354, frame count 610000, epsilon 0.512, loss 0.00016\n",
      "running reward: 0.11 at episode 5442, frame count 620000, epsilon 0.504, loss 0.00160\n",
      "running reward: 0.13 at episode 5527, frame count 630000, epsilon 0.496, loss 0.00028\n",
      "running reward: 0.26 at episode 5605, frame count 640000, epsilon 0.488, loss 0.00050\n",
      "running reward: 0.27 at episode 5685, frame count 650000, epsilon 0.480, loss 0.00183\n",
      "running reward: 0.11 at episode 5777, frame count 660000, epsilon 0.472, loss 0.00031\n",
      "running reward: 0.16 at episode 5857, frame count 670000, epsilon 0.464, loss 0.00040\n",
      "running reward: 0.18 at episode 5937, frame count 680000, epsilon 0.456, loss 0.00052\n",
      "running reward: 0.31 at episode 6010, frame count 690000, epsilon 0.448, loss 0.00314\n",
      "running reward: 0.19 at episode 6096, frame count 700000, epsilon 0.440, loss 0.00265\n",
      "running reward: 0.27 at episode 6170, frame count 710000, epsilon 0.432, loss 0.00075\n",
      "running reward: 0.38 at episode 6232, frame count 720000, epsilon 0.424, loss 0.00016\n",
      "running reward: 0.37 at episode 6302, frame count 730000, epsilon 0.416, loss 0.00162\n",
      "running reward: 0.38 at episode 6366, frame count 740000, epsilon 0.408, loss 0.00327\n",
      "running reward: 0.22 at episode 6452, frame count 750000, epsilon 0.400, loss 0.00039\n",
      "running reward: 0.25 at episode 6530, frame count 760000, epsilon 0.392, loss 0.00046\n",
      "running reward: 0.28 at episode 6605, frame count 770000, epsilon 0.384, loss 0.00037\n",
      "running reward: 0.24 at episode 6684, frame count 780000, epsilon 0.376, loss 0.00307\n",
      "running reward: 0.29 at episode 6757, frame count 790000, epsilon 0.368, loss 0.00074\n",
      "running reward: 0.29 at episode 6828, frame count 800000, epsilon 0.360, loss 0.00036\n",
      "running reward: 0.30 at episode 6905, frame count 810000, epsilon 0.352, loss 0.00045\n",
      "running reward: 0.22 at episode 6986, frame count 820000, epsilon 0.344, loss 0.00161\n",
      "running reward: 0.24 at episode 7061, frame count 830000, epsilon 0.336, loss 0.00106\n",
      "running reward: 0.34 at episode 7131, frame count 840000, epsilon 0.328, loss 0.00197\n",
      "running reward: 0.38 at episode 7196, frame count 850000, epsilon 0.320, loss 0.00414\n",
      "running reward: 0.28 at episode 7272, frame count 860000, epsilon 0.312, loss 0.00418\n",
      "running reward: 0.15 at episode 7357, frame count 870000, epsilon 0.304, loss 0.00138\n",
      "running reward: 0.36 at episode 7423, frame count 880000, epsilon 0.296, loss 0.00024\n",
      "running reward: 0.46 at episode 7490, frame count 890000, epsilon 0.288, loss 0.00087\n",
      "running reward: 0.38 at episode 7555, frame count 900000, epsilon 0.280, loss 0.00640\n",
      "running reward: 0.44 at episode 7616, frame count 910000, epsilon 0.272, loss 0.00033\n",
      "running reward: 0.45 at episode 7682, frame count 920000, epsilon 0.264, loss 0.00325\n",
      "running reward: 0.44 at episode 7747, frame count 930000, epsilon 0.256, loss 0.00158\n",
      "running reward: 0.49 at episode 7805, frame count 940000, epsilon 0.248, loss 0.00105\n",
      "running reward: 0.58 at episode 7863, frame count 950000, epsilon 0.240, loss 0.00060\n",
      "running reward: 0.32 at episode 7936, frame count 960000, epsilon 0.232, loss 0.00054\n",
      "running reward: 0.48 at episode 7995, frame count 970000, epsilon 0.224, loss 0.00096\n",
      "running reward: 0.64 at episode 8046, frame count 980000, epsilon 0.216, loss 0.00062\n",
      "running reward: 0.60 at episode 8107, frame count 990000, epsilon 0.208, loss 0.00084\n",
      "running reward: 0.50 at episode 8163, frame count 1000000, epsilon 0.200, loss 0.00316\n"
     ]
    }
   ],
   "source": [
    "# Experience replay buffers\n",
    "action_history = []\n",
    "state_history = []\n",
    "state_next_history = []\n",
    "rewards_history = []\n",
    "done_history = []\n",
    "\n",
    "episode_reward_history = []\n",
    "running_reward = 0\n",
    "episode_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "MAX_EPISODES = 50000\n",
    "\n",
    "while True and episode_count < MAX_EPISODES:  # Run until solved\n",
    "    state = np.array(env.reset())\n",
    "    episode_reward = 0\n",
    "\n",
    "    for timestep in range(1, max_steps_per_episode):\n",
    "        \n",
    "        frame_count += 1\n",
    "\n",
    "        # Use epsilon-greedy for exploration\n",
    "        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
    "            # Take random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = model(state_tensor, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "\n",
    "        # Decay probability of taking random action\n",
    "        if frame_count < epsilon_greedy_frames:\n",
    "          epsilon -= epsilon_interval_1 / epsilon_greedy_frames\n",
    "          epsilon = max(epsilon, epsilon_min_1)\n",
    "        \n",
    "        if frame_count > epsilon_greedy_frames and frame_count < 2 * epsilon_greedy_frames:\n",
    "          epsilon -= epsilon_interval_2 / epsilon_greedy_frames\n",
    "          epsilon = max(epsilon, epsilon_min_2)\n",
    "        \n",
    "        if frame_count > 2 * epsilon_greedy_frames:\n",
    "          epsilon -= epsilon_interval_3 / epsilon_greedy_frames\n",
    "          epsilon = max(epsilon, epsilon_min_3)\n",
    "          \n",
    "\n",
    "        # Apply the sampled action in our environment\n",
    "        state_next, reward, done, _ = env.step(action)\n",
    "        state_next = np.array(state_next)\n",
    "\n",
    "        episode_reward += reward\n",
    "\n",
    "        # Save actions and states in replay buffer\n",
    "        action_history.append(action)\n",
    "        state_history.append(state)\n",
    "        state_next_history.append(state_next)\n",
    "        done_history.append(done)\n",
    "        rewards_history.append(reward)\n",
    "        state = state_next\n",
    "\n",
    "        # Update every 20th frame and once batch size is over 32\n",
    "        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
    "\n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            state_next_sample = np.array([state_next_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor(\n",
    "                [float(done_history[i]) for i in indices]\n",
    "            )\n",
    "\n",
    "            # Build the updated Q-values for the sampled future states\n",
    "            # Use the target model for stability\n",
    "            future_rewards = model_target.predict(state_next_sample)\n",
    "            # Q value = reward + discount factor * expected future reward\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(\n",
    "                future_rewards, axis=1\n",
    "            )\n",
    "\n",
    "            # If final frame set the last value to -1\n",
    "            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
    "\n",
    "            # Create a mask so we only calculate loss on the updated Q-values\n",
    "            masks = tf.one_hot(action_sample, num_actions)\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Train the model on the states and updated Q-values\n",
    "                q_values = model(state_sample)\n",
    "\n",
    "                # Apply the masks to the Q-values to get the Q-value for action taken\n",
    "                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                # Calculate loss between new Q-value and old Q-value\n",
    "                loss = loss_function(updated_q_values, q_action)\n",
    "\n",
    "            # Backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if frame_count % update_target_network == 0:\n",
    "            # update the the target network with new weights\n",
    "            model_target.set_weights(model.get_weights())\n",
    "            # Log details\n",
    "            template = \"running reward: {:.2f} at episode {}, frame count {}, epsilon {:.3f}, loss {:.5f}\"\n",
    "            print(template.format(running_reward, episode_count, frame_count, epsilon, loss))\n",
    "\n",
    "        # Limit the state and reward history\n",
    "        if len(rewards_history) > max_memory_length:\n",
    "            del rewards_history[:1]\n",
    "            del state_history[:1]\n",
    "            del state_next_history[:1]\n",
    "            del action_history[:1]\n",
    "            del done_history[:1]\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Update running reward to check condition for solving\n",
    "    episode_reward_history.append(episode_reward)\n",
    "    if len(episode_reward_history) > 100:\n",
    "        del episode_reward_history[:1]\n",
    "    running_reward = np.mean(episode_reward_history)\n",
    "\n",
    "    episode_count += 1\n",
    "\n",
    "    if running_reward > 18:  # Condition to consider the task solved\n",
    "        print(\"Solved at episode {}!\".format(episode_count))\n",
    "        save_model(episode_count)\n",
    "        break\n",
    "        \n",
    "    # save model\n",
    "    if episode_count % 5000 == 0:\n",
    "        save_model(episode_count)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
